

#TRY 1
#####CONFIG##### = 
ysKeyName='topic_wx_00',userNorm = None,urlNorm = None,hashNormalise=False,digitNormalise=False
features = Pipeline([\
            ('docs',tran.DocsExtractor(transformedTweetKeyName = 'normalised_string')),\
            ('count',tran.CountVectorizer(tokenizer=string.split,ngram_range=(1, 1) ,binary=True))])
clf =Pipeline([\
            ('features',features),
            ('clf',LogisticRegression(penalty = 'l1',C = 1.0))])
#####SCORES#####
Breakdown by class:
positive 	15418
neutral 	0
negative 	13658
File: wx-gold.tsv -- no errors found


Gold standard: 29076 lines
               29076 unique
Breakdown by class:
positive 	14713
neutral 	0
negative 	14363


Confusion table:
gs \ pred| positive| negative|  neutral
---------------------------------------
 positive|    12310|     2403|        0
 negative|     3108|    11255|        0
  neutral|        0|        0|        0


Scores:
class	                       prec	              recall     fscore
positive 	(12310/15418) 0.7984	 (12310/14713) 0.8367	 0.8171	
negative 	(11255/13658) 0.8241	 (11255/14363) 0.7836	 0.8033	
neutral 	       (0/0) 0.0000	        (0/0) 0.0000	 0.0000	
-----------------------------------------------------------------------
average(pos and neg)                                             0.8102

#TRY 2
with digit normalisation ---> Got WORSE only .002 faverga

#TRY 3
with hash normalisation ---> Got SLIGHLTY better only .002 faverga

#TRY 4 WITH BIGRAMS
Confusion table:
gs \ pred| positive| negative|  neutral
---------------------------------------
 positive|    12274|     2439|        0
 negative|     2846|    11517|        0
  neutral|        0|        0|        0


Scores:
class	                       prec	              recall     fscore
positive 	(12274/15120) 0.8118	 (12274/14713) 0.8342	 0.8228	
negative 	(11517/13956) 0.8252	 (11517/14363) 0.8019	 0.8134	
neutral 	       (0/0) 0.0000	        (0/0) 0.0000	 0.0000	
-----------------------------------------------------------------------
average(pos and neg)                                             0.8181	


#TRY 5 - With Clusters ---> Only 320 in live corpus classified about weather, promising
wordgrams = Pipeline([\
            ('docs',tran.DocsExtractor(transformedTweetKeyName = 'normalised_string')),\
            ('count',tran.CountVectorizer(tokenizer=string.split,ngram_range=(1, 2) ,binary=True))])
cmuClusterFeatures = Pipeline([\
            ('clusters',tran.ClusterExtractor()),\
            ('count',tran.CountVectorizer(tokenizer=string.split,ngram_range=(1, 1) ,binary=False,\
                     vocabulary = helper.loadJSONfromFile(helper.getProjectPath() + '/wxtalk/resources/lexicons/CMU/CMU-cluster-vocab.json')))])
GUMLTClusterFeatures = Pipeline([\
            ('clusters',tran.ClusterExtractor(['collapsed_token_list','raw_token_list','normalised_token_list'])),\
            ('count',tran.CountVectorizer(tokenizer=string.split,ngram_range=(1, 1) ,binary=False,\
                     vocabulary = helper.loadJSONfromFile(helper.getProjectPath() + '/wxtalk/resources/lexicons/CMU/CMU-cluster-vocab.json')))])   
features = FeatureUnion([
            ('word-gram-count',wordgrams ),
            #('stem-gram-count',KLUEstems),
            #('pos-count',posCounts)
            ('cmu-cluster',GUMLTClusterFeatures),
            ]) 
clf =Pipeline([\
            ('features',features),
            ('clf',LogisticRegression(penalty = 'l1',C = 1.0))])
